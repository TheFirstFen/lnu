### 1
Skriv ett program i Go som skapar en goroutine som skriver ut en text paÌŠ skaÌˆrmen

```go 
package main

import (
    "fmt"
    "sync"
    )

func main() {
    wg := sync.WaitGroup{}
    wg.Add(1)
    go func() {
        defer wg.Done()
        fmt.Println("Hello there")
    }()
    wg.Wait()

}
```

### 2
Skriv ett program i Go som laÌˆser ett vaÌˆrde fraÌŠn en kanal och skriver ut det paÌŠ skaÌˆrmen

```go
package main

import (
    "fmt"
    "sync"
)

func main() {
    strChan := make(chan string, 1)

    strChan <- "Hello there" // WRITES
    x := <- strChan // READS

    close(strChan)
    fmt.Println(x)
}


```
### 3
Var aÌˆr GIL i Python och hur paÌŠverkar det traÌŠdade program i Python?

### 4
Skriv ett program i Go som kan ge upphov till ett data race

```go
package main

import (
    "sync"
    "fmt"
)

func main() {
    wg := sync.WaitGroup{}

    num := 0
    expected := 100

    for i := 0; i < expected; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            num++
        }()
    }

    wg.Wait()

    fmt.Println("Does 'num' equal 'expected'?", num == expected)
}
```

I detta program skapar vi 100 goroutines som inkrementerar 'num' med 1. FÃ¶rvÃ¤ntningen Ã¤r att 'num == expected' inte alltid kommer vara sann eftersom vi har flera goroutines som lÃ¤ser och skriver till 'num' samtidigt. Detta riskerar att exempelvis tvÃ¥ goroutines lÃ¤ser vÃ¤rdet 5 fÃ¶r att sedan skriva 6 till minnesadressen medan det egentliga vÃ¤rdet bÃ¶r vara 7. Detta Ã¤r ett typexempel pÃ¥ ett race condition. 

### 5
Implementera Petersonâ€™s algorithm i Go-liknande kod.

runtime gosched? 

### 6
Implementera en producent i Go-liknande kod som anvaÌˆnder mutex foÌˆr oÌˆmesidig uteslutning

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
    var lock sync.Mutex
    var wg sync.WaitGroup
    var lst []int

    for i := 0; i < 2; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            producer(0, 10, &lock, &lst)
        }()
    }
    wg.Wait()
    fmt.Println(lst)
}



func producer(start int, end int, lock *sync.Mutex, lst *[]int) {
    for i := start; i <= end; i++ {
        lock.Lock()
        *lst = append(*lst, i)
        lock.Unlock()
    }
}
```



### 7
Implementera en producent i Go-liknande kod som anvaÌˆnder kanaler foÌˆr oÌˆmesidig uteslutning
```go
package main

import (
    "sync"
    "fmt"
)

func main() {
    var lock sync.Mutex
    var lst []int
    gate := make(chan any, 1)

    for i := 0; i < 2; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            producer(0, 10, gate, &lst)
        }()
    }
    wg.Wait()
    fmt.Println(lst)
    close(gate)
}

func producer(start int, end int, gate chan any, lst *[]int) {
    for i := start; i <= end; i++ {
        gate <- nil
        *lst = append(*lst, i)
        <- gate
    }
}
```



### 8
Ge ett exempel i Go daÌˆr tvaÌŠ goroutines delar en variabel och anvaÌˆnder en mutex foÌˆr att (korrekt) skydda tillgaÌŠngen

```go
package main

import (
    "sync"
    "fmt"
)

func main() {
    var wg sync.WaitGroup
    var lock sync.Mutex

    x := 0

    for i := 0; i < 2; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            incrementor(&x, &lock)
        }()
    }
    wg.Wait()

    fmt.Println("Does x equal 100?", x == 100)
}

func incrementor(x *int, lock *sync.Mutex) {
    for {
        lock.Lock()
        if *x >= 100 {
            lock.Unlock()
            return
        } 
        *x++
        lock.Unlock()
    }
}
```
I detta program har vi tvÃ¥ goroutines som kontinuerligt inkrementerar 'x' tills 'x == 100' Ã¤r sant. Rutinerna anvÃ¤nder mutex lÃ¥s fÃ¶r att skydda oss frÃ¥n race conditions.

### 9
Ge ett exempel paÌŠ ett program i Go med kanaler som kan leda till deadlock

```go
package main

import (
	"fmt"
	"math/rand"
	"sync"
)

func main() {
    var wg sync.WaitGroup
    c := make(chan int, 5)

    random := rand.Intn(11)

    for i := 0; i < random; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            writeToChan(c)
        }()
    }
    
    wg.Wait()
    fmt.Println("We made it")
    close(c)
    
}

func writeToChan(c chan<- int) {
    c <- 1
}
```

### 10
Ge ett exempel paÌŠ ett program i Go utan kanaler som kan leda till deadlock

```go
package main

import (
    "sync"
)

func main() {
    var l1 sync.Mutex
    var l2 sync.Mutex
    var wg sync.WaitGroup

    wg.Add(1)
    go func() { // GO ROUTINE 1 (G1)
        defer wg.Done()
        l1.Lock()
        l2.Lock()

        l1.Unlock()
        l2.Unlock()
    }()

    wg.Add(1)
    go func() { // GO ROUTINE 2 (G2)
        defer wg.Done()
        l2.Lock()
        l1.Lock()

        l1.Unlock()
        l2.Unlock()
    }()
    wg.Wait()
}
```

I detta programmet har vi tvÃ¥ gorutiner dÃ¤r G1 fÃ¶rst lÃ¥ser l1, sedan l2. G2 lÃ¥ser fÃ¶rst l2, sedan l1. I detta program finns en risk att G1 lÃ¥ser l1 och G2 lÃ¥ser l2 samtidigt. Det betyder att G1 kommer vÃ¤nta pÃ¥ att l2 ska lÃ¥sas upp, och G2 pÃ¥ l1, vilket betyder att bÃ¥da kommer vÃ¤nta i all evighet vilket skapar ett deadlock.

### 11
Implementera en parallel prefix sum med goroutines i Go

### 12
Implementera en parallel prefix scan med goroutines i Go

### 13
Implementera en parallel odd-even transposition sort med goroutines i Go

### 14
Visa hur en for-loop kan paralleliseras i Go med goroutines

```go
package main

import (
    "sync"
    "time"
    "fmt"
)

func main() {
    var wg sync.WaitGroup

    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(i int) {
            defer wg.Done()
            printer(i)
        }(i)
    }
    wg.Wait()
}

func printer(i int) {
    time.Sleep(time.Second)
    fmt.Println(i)
}
```

### 15
Hur kan en barrier impementeras med mutex? Visa i Go-liknande kod

### 16
Hur kan en barrier impementeras med kanaler? Visa i Go-liknande kod

### 17
Ge en concurrent/parallel algoritm foÌˆr att hitta det minsta vaÌˆrdet i en lista i Go-liknande kod

```go
package main

import (
	"fmt"
	"math"
	"sync"
)


func main() {
    var wg sync.WaitGroup
    reportChan := make(chan int)
    indexChan := make(chan [2]int, 10)
    doneChan := make(chan any)

    lst := []int{-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -2, -10, 13, 14}

    intervall := 3
    valuesOnReportChan := len(lst) / intervall
    if len(lst) % intervall != 0 {
        valuesOnReportChan++
    }
    goroutines := 4

    wg.Add(1)
    go func() {
        defer wg.Done()
        sendIndexes(intervall, len(lst), indexChan)
    }()

    for i := 0; i < goroutines; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            worker(&lst, indexChan, reportChan, doneChan)
        }()
    }

    min := math.MaxInt
    for i := 0; i < valuesOnReportChan; i++ {
        x :=  <- reportChan
        if x < min {
            min = x
        }
    }
    close(doneChan)
    wg.Wait()
    fmt.Println("Smallest value: ", min)

}

func sendIndexes(intervall int, lstLen int, indexChan chan<- [2]int) {
    if intervall > lstLen {
        panic("intervalls may not exceed the lenght of the list")
    }
    start := 0
    end := intervall
    for end <= lstLen {
        l := [2]int{start, end}
        indexChan <- l
        start = end
        end += intervall
    }
    if end > lstLen {
        l := [2]int{start, lstLen}
        indexChan <- l
    }
}

func worker(lst *[]int, indexChan <-chan [2]int, reportChan chan<- int, doneChan chan any) {
    for {
        select {
        case _, ok := <- doneChan:
            if !ok {
                return
            }
        case l := <- indexChan:
            start, end := l[0], l[1]
            min := math.MaxInt
            for i := start; i < end; i++ {
                if (*lst)[i] < min {
                    min = (*lst)[i]
                }
            }
            reportChan <- min
        }
    }
    
}
```

### 18
Vad innebaÌˆr en atomaÌˆr variabel i Go
Det Ã¤r en variabel som du kan utfÃ¶ra operationer pÃ¥ pÃ¥ en atomÃ¤r nivÃ¥. AtomÃ¤r nivÃ¥ syftar pÃ¥ ett villkor fÃ¶r variabeln som garanterar att tiden det tar att gÃ¶ra en operation Ã¤r sÃ¥ pass kort att inga race conditions sker om du skulle utfÃ¶ra flera operationer pÃ¥ variabeln frÃ¥n olika trÃ¥dar samtidigt. 

### 19
Visa hur en variabels vaÌˆrde kan jaÌˆmfoÌˆras och bytas atomaÌˆrt i Go

```go
package main

import (
	"fmt"
	"sync/atomic"
)

func main() {
	var x atomic.Int64
	x.Store(3)
    x.CompareAndSwap(3, 5) // LOOK HERE
    
    fmt.Println(x.Load() == 5)
}
```

### 20
FoÌˆrklara vad happens before i en minnesmodell
Vad menar han?

### 21
Vilka antaganden kan goÌˆras om tvaÌŠ traÌŠdar modiferar en delad variabel (enligt Javas minnes-modell).

### 22
FoÌˆrklara begreppet multicore cpu

En 'multicore cpu' syftar pÃ¥ en flerkÃ¤rnig processorenhet. KÃ¤rnorna pÃ¥ processorn Ã¤r en slags processor i sig och mÃ¶jliggÃ¶r parallell exekvering. 

### 23
Vad aÌˆr skillnanden mellan concurrency och parallelism?

Parallelism syftar pÃ¥ parallella exekveringar av olika processer och/eller trÃ¥dar i ett program. Exempelvis kan tvÃ¥ trÃ¥dar exekveras och kÃ¶ras parallelt dÃ¤r trÃ¥d 1 berÃ¤knar 1 + 1 och trÃ¥d 2 1 + 2. Concurrency, eller samtidighet pÃ¥ svenska, syftar pÃ¥ sjÃ¤lva strukturen och logiken i koden som mÃ¶jliggÃ¶r att parallella processer kan kÃ¶ras. Ett exempel pÃ¥ 'concurrent programming' Ã¤r utformningen av den logik som gÃ¶r att parallella processer kan lÃ¤sa och skriva till samma minne pÃ¥ ett korrekt och sÃ¤kert vis.

Inte helt hundra...

### 24
Vad betyder det att ett problem aÌˆr embarrassingly parallel?

Det betyder att problemet Ã¤r vÃ¤ldigt lÃ¤tt att parallellisera. Detta kÃ¤nnetecknas genom att problemet kan delas upp i mindre delar som Ã¤r oberoende frÃ¥n varandra vilket gÃ¶r det lÃ¤tt att integrera parallellism. Detta Ã¤r ett slags idealtillstÃ¥nd nÃ¤r man anvÃ¤nders sig av parallelism. 

### 25
Ge exempel paÌŠ ett problem som aÌˆr embarrassingly parallel

Med hjÃ¤lp av en monte carlo simulering kan man approximera pi genom att slumpmÃ¤ssigt ansÃ¤tta punkter i en kvadrat med sidan 2 lÃ¤ngdenehter som har en innersluten cirkel med radien 1 lÃ¤ngdenhet. Kvoten mellan det totala antalet punkter och de punkter som hamnar i cirkeln kommer ge en approximation av pi. Detta problem kan lÃ¤tt parallelliseras genom att lÃ¥ta ett set processer generera dessa slumpmÃ¤ssiga punkter.


### 26
FoÌˆrklara begreppet operativsystem

Begreppet 'operativsystem' Ã¤r ett mjukvaruprogram som finns i mer eller mindre alla dagens datorer. Programmets syfte Ã¤r att ge ett anvÃ¤ndarvÃ¤nligt grÃ¤nssnitt med funktioner som gÃ¶r datorn anvÃ¤ndarbar fÃ¶r en vanlig person. Programmet hanterar uppgifter som programexekvering, resursallokering, kommunikation med I/O, datahantering, etc.

### 27
Vad betyder det att ett operativsystem kan ses som ett interface mot datorn?

### 28
Vad betyder det att ett operativsystem kan ses som ett kontrollsystem foÌˆr datorn?

Det betyder att operativsystemet kontrollerar vad som fÃ¥r hÃ¤nda pÃ¥ en dator. Operativsystemet ger en anvÃ¤ndare mÃ¶jligheter att Ã¤ndra mÃ¥nga saker pÃ¥ en dator i form av exempelvis vad som sparas, samtidigt som den begrÃ¤nsar anvÃ¤ndaren i flera avseenden. Exempelvis kanske det inte Ã¤r lÃ¤mpligt fÃ¶r en "vanlig" anvÃ¤ndare att ha direkt tillgÃ¥ng till minnet dÃ¤r hen kan skriva till minnesadresser och Ã¤ndra i minnesstrukturen dÃ¥ personen fÃ¶rmodligen inte vet vad den gÃ¶r, vilket kan fÃ¥ oÃ¶nskade konsekvenser. DÃ¤rmed Ã¤r det bÃ¤ttre att lÃ¥ta ett 'kontrollsystem' som ett operativsystem att gÃ¶ra det jobbet med mycket annat som gÃ¶r att datorn funkar som den ska.

### 29
Vad aÌˆr skillnaden paÌŠ system mode och user mode?

### 30
Ange fem tillstaÌŠnd en process kan befinna sig i och foÌˆrklara vad de innebaÌˆr

- new - Processen Ã¤r i ett tillstÃ¥nd av att ha precis skapats.
- ready - Processen Ã¤r redo att kÃ¶ras
- run - Processen kÃ¶r
- wait - Processen vÃ¤ntar in nÃ¥got fÃ¶r att fÃ¥ kÃ¶ra igen
- terminate - Processen avslutas

### 31
FoÌˆrklara begreppen stack, heap, data och text i relation till processer

Stack - ?
Heap - Syftar pÃ¥ det dynamiska minne som anvÃ¤nds av processen
Data - Syftar pÃ¥ de initialiserade och ej initialiserade globala och statiska variabler
Text - Syftar pÃ¥ koden som ska kÃ¶ras av processen

### 32
Vad lagras i ett processkontrollblock (PCB)?

Det Ã¤r en datastruktur som sparar information om en process. Exempel pÃ¥ sÃ¥dan information Ã¤r processens nummer, dess tillstÃ¥nd, minnesbegrÃ¤nsningar mm.

### 33
Vad aÌˆr en context switch?

En context switch Ã¤r processen att pausa en process och spara dess tillstÃ¥nd fÃ¶r att sedan ladda upp och och kÃ¶ra en annan process. Denna procedur sker kontinuerligt i ett operativsystem som mÃ¶jliggÃ¶r, endast till synes, en parallell exekvering av exempelvis tvÃ¥ olika program.

### 34
FoÌˆrklara vad som haÌˆnder under en context switch

FÃ¶r ett set av processer/trÃ¥dar som kÃ¶rs av en processor sÃ¥ fÃ¶rflyttar processorn sin uppmÃ¤rksamhet mellan processerna/trÃ¥darna kontinuerligt och ofta fÃ¶r att ge intrycket att processerna/trÃ¥darna kÃ¶rs parallellt. Under en context switch sÃ¥ kÃ¶r processorn en godtycklig process/trÃ¥d en viss tid. Efter det pausar den processen/trÃ¥den fÃ¶r att sedan spara dess nuvarande tillstÃ¥nd till minnet. Den gÃ¥r sedan vidare till nÃ¤sta process/trÃ¥d fÃ¶r att ladda upp dess tillstÃ¥nd och kÃ¶ra den en viss tid och sÃ¥ vidare. 

### 35
Vad innebaÌˆr schemalaÌˆggning av en process?

### 36
NaÌˆr tas beslut om schemalaÌˆggning?

### 37
Vad goÌˆr dispatcher?

### 38
Ange tre kriterier som kan anvaÌˆndas foÌˆr att bestaÌˆmma vilken schemalaÌˆggningsalgoritm som skall anvaÌˆndas

### 39
Vad betyder det att en process aÌˆr I/O bound?

Det betyder att en process Ã¤r begrÃ¤nsad av input/output som disk, anvÃ¤ndarinput frÃ¥n mus och tangentbord, nÃ¤tverk etc

### 40
Vad betyder det att en process aÌˆr CPU bound?

Det betyder att en process Ã¤r begrÃ¤nsad av processorns interna resurser som antalet kÃ¤rnor, processorns hastighet, cache etc.

### 41
FoÌˆrklara hur schemalaÌˆggning sker om First Come, First Served anvaÌˆnds

### 42
FoÌˆrklara hur schemalaÌˆggning sker om Round Robin anvaÌˆnds

### 43
FoÌˆrklara preemptive schemalaÌˆggning

### 44
FoÌˆrklara non-preemptive schemalaÌˆggning

### 45
Vad aÌˆr ett quantum?

### 46
Hur paÌŠverkar ett quantum schemalaÌˆggningen?

### 47
Vad aÌˆr viktigt att taÌˆnka paÌŠ naÌˆr man bestaÌˆmmer quantum?

### 48
FoÌˆrklara begreppen isolation och encapsulation i relation till processer

### 49
Vad aÌˆr skillnaden paÌŠ en process och en traÌŠd?


En process Ã¤r en sjÃ¤vstÃ¤ndig enhet som innehÃ¥ller en egen uppsÃ¤ttning resurser som den kan arbeta med och anvÃ¤nds fÃ¶r att kÃ¶ra ett program eller applikation. Processer Ã¤r isolerade till varandra och kan dÃ¤rmed inte kommunicera. TrÃ¥dar Ã¤r en del av en process och kan kÃ¶ras parallellt fÃ¶r att utfÃ¶ra uppgifter dÃ¤r trÃ¥darna kan kommunicera med varandra och nyttja resurserna som finns i processen. 

### 50
Vad anvaÌˆnds stacken till i en traÌŠd?

### 51
Var aÌˆr skillnaden paÌŠ user-level- och kernel-level-traÌŠdar?

### 52
FoÌˆrklara begreppet blockerande anrop

### 53
Vad haÌˆnder om en user-level traÌŠd goÌˆr ett blockerande anrop?

### 54
Vad haÌˆnder om en kernel-level traÌŠd goÌˆr ett blockerande anrop?

### 55
VarfoÌˆr vill man dela minne mellan traÌŠdar?

Ibland finns det ett intresse i att trÃ¥dar kommunicerar med varandra. Det krÃ¤ver nÃ¥gon form av gemensamt minne fÃ¶r trÃ¥darna att skriva och lÃ¤sa frÃ¥n fÃ¶r att kommunikationen ska kunna ta plats.

### 56
Vad aÌˆr skillnaden mellan att dela minne mellan traÌŠdar och processer?

Skillnaden Ã¤r att trÃ¥dar delar samma minne inom en process medan processer har separata minnesutrymmen som inte delas. Det innebÃ¤r att trÃ¥dar kan dela gemensam data direkt genom exempelvis variabler. Processer kommunicerar genom andra metoder som delade minnessegment eller genom Inter Process Communication IPC.

### 57
FoÌˆrklara begreppet sequentially consistent i relation till minne

Det Ã¤r en minnesmodell som beskriver hur minnet mÃ¥ste ordnas i ett parallellt system fÃ¶r att minnesoperationer ska ske i nÃ¥gon sekventiell ordning. NÃ¤r man programmerar seriellt sker alltid minnesoperationer i en sekventiell ordning eftersom du endast kan gÃ¶ra en minnesoperation i taget. Inom concurrent programming finns det mÃ¶jlighet att utfÃ¶ra flera minnesoperationer samtidigt med trÃ¥dar vilket kan orsaka race conditions. DÃ¤rmed Ã¤r det viktigt att de minnesoperationer som gÃ¶rs av parallellt exekverade trÃ¥dar sker en i taget i nÃ¥gon ordning sÃ¥ att minnet beter sig som vi fÃ¶rvÃ¤ntar oss. 

### 58
Vad innebaÌˆr ett data race/race condition?

Ett sÃ¥ kallat race condition Ã¤r ett fenomen som fÃ¶rekommer inom exempelvis 'concurrent programming' dÃ¤r parallella processer riskerar att skapa inkonsekventa beteenden i ett program pÃ¥ grund av den timing som processerna sker. Exempelvis om tvÃ¥ processer ska inkrementera vÃ¤rdet pÃ¥ en variabel x = 0 med 1 fÃ¶rvÃ¤ntar vi oss att x = 2 nÃ¤r processerna Ã¤r fÃ¤rdiga. Dock om processerna sker samtidigt i den mÃ¥n att bÃ¥da hinner lÃ¤sa vÃ¤rdet 0 fÃ¶r att sedan skriva vÃ¤rdet 1 till x kommer x ha det slutgiltiga vÃ¤rdet 1. Detta blir ett inkonsekvent beteende som inte Ã¤r Ã¶nskat.

### 59
Vad aÌˆr en kritisk sektion?

En kritisk sektion Ã¤r en sektion i koden dÃ¤r den delade datan fÃ¶r de parallella processerna/trÃ¥darna som kÃ¶rs behandlas och/eller hÃ¤mtas. Dessa sektioner krÃ¤ver ofta exklusivitet vilket betyder att sektionerna endast fÃ¥r kÃ¶ras av en trÃ¥d/process i taget. 

### 60
Ge exempel paÌŠ ett data race

SÃ¤g att tvÃ¥ parallellt exekverade processer vill inkrementera variabeln x = 0 med 1. VÃ¥r fÃ¶rvÃ¤ntning Ã¤r att nÃ¤r processerna Ã¤r klara kommer x ha tilldelats vÃ¤rdet 2. Det finns dock en risk att bÃ¥da processerna hinner lÃ¤sa vÃ¤rdet 0 frÃ¥n variabeln x vilket betyder att bÃ¥da kommer skriva vÃ¤rdet 1 till x. Detta betyder att det slutgiltiga vÃ¤rdet fÃ¶r x Ã¤r 1 vilket Ã¤r inkosekvent med det fÃ¶rvÃ¤ntade resultatet. Detta problem Ã¤r ett typexempel pÃ¥ ett data race.

### 61
Vad innebaÌˆr oÌˆmsesidig uteslutning?

Det innebÃ¤r att ett visst segment i koden endast fÃ¥r kÃ¶ras av en process i taget. Det vill sÃ¤ga: alla andra processer som kÃ¶rs parallellt Ã¤r uteslutna frÃ¥n segmentet tills den process som Ã¤r i segmentet Ã¤r fÃ¤rdig. Exempelvis om flera processer ska skriva till variabeln x, fÃ¶rutsÃ¤tter detta Ã¶msesidig uteslutning eftersom race conditions annars kan skapas.

### 62
Hur kan oÌˆmesidig uteslutning loÌˆsas? ge exempel.

Man kan anvÃ¤nda lÃ¥svariabler som kommunicerar ifall en process fÃ¥r gÃ¥ in i kodsegmentet som krÃ¤ver Ã¶msesidig uteslutning. Detta fÃ¶rutsÃ¤tter att sjÃ¤lva lÃ¥sningsprocessen Ã¤r atomÃ¤r. Om inte sÃ¥ kommer race conditions skapas dÃ¤r fler Ã¤n en process riskerar att komma in i segmentet.

En annan metod Ã¤r att anvÃ¤nda sig av strikta vÃ¤xlingar (strict alternations) dÃ¤r man har en variabel 'turn' som kommunicerar ifall en process fÃ¥r kÃ¶ra ett kodsegment. Detta funkar dock bara fÃ¶r tvÃ¥ processer. Processen som kÃ¶r kodsegmentet som krÃ¤ver Ã¶msesidig uteslutning kan Ã¤ndra variabeln 'turn' sÃ¥ att den andra processen fÃ¥r kÃ¶ra och vise versa.

### 63
FoÌˆrklara hur strict alteration foÌˆrsoÌˆker loÌˆsa oÌˆmesidig uteslutning

Metoden 'strict alteration' anvÃ¤nder sig av en variabel 'turn' som kommunicerar fÃ¶r tvÃ¥ processer vem som  fÃ¥r kÃ¶ra ett kodsegment som krÃ¤ver Ã¶msesidig uteslutning. SÃ¤g att process A fÃ¥r kÃ¶ra nÃ¤r 'turn' Ã¤r lika med 0 och process B nÃ¤r 'turn' Ã¤r lika med 1. Om 'turn' till en bÃ¶rjan Ã¤r 0, kommer process A fÃ¥ kÃ¶ra kodsegmentet. NÃ¤r process A Ã¤r klar skriver den 1 till 'turn' och process B fÃ¥r kÃ¶ra osv.

### 64
FoÌˆrklara Petersonâ€™s algoritm foÌˆr oÌˆmsesidig uteslutning

### 65
Vad innebaÌˆr progression i relation till oÌˆmesidig uteslutning?



### 66
Vad innebaÌˆr begraÌˆnsad vaÌˆntan i relation till oÌˆmesidig uteslutning?

### 67
Vad aÌˆr en semafor?

En semafor Ã¤r en variabel som agerar som ett lÃ¥s fÃ¶r att styra hur mÃ¥nga processer/trÃ¥dar som fÃ¥r tillgÃ¥ng till exempelvis en kritisk sektion.

### 68
Vad aÌˆr ett mutex lock?

Ett 'mutex lock' Ã¤r en binÃ¤r semafor som tillÃ¥ter en lÃ¥sning och en upplÃ¥sning i taget, dÃ¤rmed 'binÃ¤r'. Den kan anvÃ¤ndas i sammanhang nÃ¤r ett moment i ett program krÃ¤ver exklusivitet. Exempelvis att Ã¤ndra vÃ¤rdet pÃ¥ en variabel krÃ¤ver eklusivitet eftersom parallella processer riskerar annars att skriva Ã¶ver varandras Ã¤ndringar.

### 69
Vad aÌˆr skillnaden mellan en binaÌˆr och en raÌˆknande semafor?

En binÃ¤r semafor tillÃ¥ter en lÃ¥sning och en upplÃ¥sning i taget. En rÃ¤knande semafor kan tillÃ¥ta fler Ã¤n en lÃ¥sning och lika mÃ¥nga upplÃ¥sningar. Exempelvis kan det finnas utrymme fÃ¶r flera processer att vara i en kritisk sektion, vilket betyder att en rÃ¤knande semafor bÃ¶r anvÃ¤ndas i stÃ¤llet fÃ¶r en binÃ¤r.

### 70
Visa hur en raÌˆknande semafor kan implementeras med hjaÌˆlp av binaÌˆra semaforer

```go
package semaphore

import (
    "sync"
)

type SemaPhore struct {
    writeLock sync.Mutex
    waitLock sync.Mutex
    N int
    counter int
}

func (s *SemaPhore) Lock() {
    s.waitLock.Lock()
    for s.counter == s.N {
        // wait...
    }
    s.writeLock.Lock()
    s.counter++
    s.writeLock.Unlock()
    s.waitLock.Unlock()
}

func (s *SemaPhore) Unlock() {
    s.writeLock.Lock()
    if s.counter <= 0 {
        panic("unlock of unlocket lock")
    }
    s.counter--
    s.writeLock.Unlock()
}
```
### 71
Vilka risker finns det med laÌŠsning?

Det finns olika risker med att lÃ¥sa. HÃ¤r Ã¤r nÃ¥gra risker. 

- Programmet kan hamna i deadlock om ett set trÃ¥dar lyckas fÃ¥ en lÃ¥sningssekvens som gÃ¶r att de mÃ¥ste vÃ¤nta pÃ¥ varandra om varje trÃ¥d hÃ¥ller ett lÃ¥s som nÃ¥gon annan behÃ¶ver, samtidigt som varje trÃ¥d efterfrÃ¥gar ett lÃ¥s som nÃ¥gon annan trÃ¥d hÃ¥ller.
- Att lÃ¥sa stÃ¶rre datastrukturer fÃ¶r exklusiv tillgÃ¥ng fÃ¶r en trÃ¥d kan orsaka ett mer sekventiellt beteende hos ett program eftersom endast en trÃ¥d kan gÃ¶ra en operation pÃ¥ datastrukturen. Det besegrar sjÃ¤lva syftet med att programmera parallellt. 
- Att gÃ¶ra lÃ¥sningar krÃ¤ver resurser som minne och uppmÃ¤rksamhet av processorn vilket blir en overhead.

### 72
Vad aÌˆr ett deadlock?

Ett deadlock Ã¤r ett tillstÃ¥nd som exempelvis en trÃ¥d kan vara i nÃ¤r trÃ¥den inte kommer vidare i sitt arbete eftersom den vÃ¤ntar pÃ¥ nÃ¥gon slags obligatorisk resurs som den aldrig tilldelas, alternativt kommer Ã¥t. Exempelvis ser vi i koden nedan hur en gorutin inte kommer vidare i sin anonyma funktion eftersom det finns inget i programmet som kommer slÃ¤ppa lÃ¥sresursen 'lock' som gÃ¶r att gorutinen kan lÃ¥sa, gÃ¶ra sitt arbete, sedan lÃ¥sa upp och avsluta.

```go
package main

import (
    "sync"
)

func main() {
    var lock sync.Mutex
    var wg sync.WaitGroup

    lock.Lock()

    wg.Add(1)
    go func() {
        defer wg.Done()
        lock.Lock()
        // DO WORK
        lock.Unlock()
    }()

    wg.Wait()
}
```

### 73
Vad innebaÌˆr det att en process aÌˆr deadlocked?
En process Ã¤r 'deadlocked' nÃ¤r den invÃ¤ntar en hÃ¤ndelse som bara en annan process kan orsaka men som aldrig orsakas. Processen kommer aldrig vidare pÃ¥ grund av detta och ligger dÃ¤rmed bara och vÃ¤ntar.

### 74
Vilka fyra villkor kraÌˆvs foÌˆr deadlock?

- Mutual exclusion
- hold and wait
- No preemption
- Circular wait

### 75
FoÌˆrklara hold and wait
Det Ã¤r ett tillstÃ¥nd nÃ¤r en process hÃ¥ller i minst en resurs samtidigt som de efterfrÃ¥gar andra resurser. FÃ¶r att en deadlock ska skapas fÃ¶r denna process fÃ¶rutsÃ¤tter det att andra processer som hÃ¥ller i nÃ¥gon av de efterfrÃ¥gade resurserna aldrig slÃ¤pper den.

### 76
FoÌˆrklara no preemption
I ett sammanhang med deadlocks innebÃ¤r det att man inte kan ta ifrÃ¥n en resurs frÃ¥n en process innan processen Ã¤r fÃ¤rdig.

Anteckningar:
Begreppet 'no preemption' innebÃ¤r att man inte kan avbryta en exekverande process fÃ¶r att sedan lÃ¥ta den Ã¥teruppta dÃ¤r den avbrÃ¶ts vid ett senare tillfÃ¤lle.

### 77
FoÌˆrklara circular wait

Det Ã¤r nÃ¤r varje process i ett set av minst tvÃ¥ processer invÃ¤ntar nÃ¥gon hÃ¤ndelse frÃ¥n nÃ¥gon/nÃ¥gra annan/andra process/er som gÃ¶r att de fÃ¥r gÃ¥ vidare i sin exekvering men som aldrig hÃ¤nder. Det blir en cirkulÃ¤r vÃ¤ntan eftersom varje process vÃ¤ntar pÃ¥ nÃ¥gon annan i ett visst led.

### 78
FoÌˆrklara hur deadlock kan foÌˆrhindras
En deadlock kan fÃ¶rhindras genom att fÃ¶rhindra ett av fÃ¶ljande eller fler:
- Mutual exclusion
- hold and wait
- No preemption
- Circular wait

### 79
Hur kan mutual exclusion foÌˆrhindras foÌˆr att undvika deadlock?

'Mutual exclusion' hÃ¥ller om det finns minst en resurs som endast en process fÃ¥r hantera i taget. SÃ¥ om alla resurser fÃ¥r hanteras av fler Ã¤n en process sÃ¥ har vi fÃ¶rhindrat 'mutual exclusion'. I regel Ã¤r det inte mÃ¶jligt att fÃ¶rhindra 'mutual exclusion' dock.

### 80
Hur kan hold and wait foÌˆrhindras foÌˆr att undvika deadlock?

Genom att exempelvis sÃ¤tta en timeout fÃ¶r nÃ¤r den mÃ¥ste sluta efterfrÃ¥ga en resurs och slÃ¤ppa de resurser som den hÃ¥ller i.  

### 81
Hur kan no preemption foÌˆrhindras foÌˆr att undvika deadlock?

Om en trÃ¥d hÃ¥ller i en resurs och efterfrÃ¥gar en annan som den mÃ¥ste vÃ¤nta pÃ¥ sÃ¥ kan man ta ifrÃ¥n (preempt) resursen som den redan hÃ¥ller i fÃ¶r att lÃ¥ta nÃ¥gon annan process ta den. Alternativt, om en trÃ¥d efterfrÃ¥gar en upptagen resurs kan den kolla ifall resursen kan bli ifrÃ¥ntagen av processen som hÃ¥ller den.

### 82
Hur kan circular wait foÌˆrhindras foÌˆr att undvika deadlock?

CirkulÃ¤r vÃ¤ntan kan fÃ¶rhindras genom att ansÃ¤tta en ordning fÃ¶r hur resurser ska tas av processerna. SÃ¤g att  vi har resurserna A, B och C som anvÃ¤nds av ett set processer. Om resurserna erhÃ¥lls av alla processer i samma ordning som de nÃ¤mndes vid namn innebÃ¤r detta att en slags kÃ¶ kommer bildas som har sitt slut vid C. Det viktiga hÃ¤r Ã¤r att vi bildar inga cykler i vÃ¥r resource allocation graph.

### 83
Ge exempel paÌŠ hur en semafor kan anvaÌˆndas saÌŠ att hold and wait inte gaÌˆller

### 84
VarfoÌˆr kan det vara problematiskt att foÌˆrhindra no preemption

Det kan vara problematiskt eftersom nÃ¤r du tvingar bort en resurs frÃ¥n en trÃ¥d som arbetar med nÃ¥gon form av minneshantering sÃ¥ kan du behÃ¶va intetgÃ¶ra det arbete som trÃ¥den redan har gjort pÃ¥ minnet. Detta intetgÃ¶randet vara svÃ¥rt att genomfÃ¶ra.

### 85
VarfoÌˆr kan det vara problematiskt att foÌˆrhindra hold and wait

### 86
FoÌˆrklara starvation

'Starvation' Ã¤r ett tillstÃ¥nd som en process kan vara i dÃ¤r processen kontinuerligt aldrig blir tilldelad en resurs som gÃ¶r att den inte kan komma vidare i sin exekvering.

### 87
Vad aÌˆr en resource allocation graph och hur anvaÌˆnds den i samband med deadlock?

En 'resource allocation graph' Ã¤r en graf bestÃ¥ende av tvÃ¥ olika sorters noder: TrÃ¥dar och resurser. I grafen anvÃ¤nder man riktade bÃ¥gar som innebÃ¤r tvÃ¥ olika saker i tvÃ¥ olika sammanhang: 

- En utgÃ¥ende bÃ¥ge frÃ¥n en trÃ¥d till en resurs innebÃ¤r att trÃ¥den efterfrÃ¥gar resursen
- En utgÃ¥ende bÃ¥ge frÃ¥n en resurs till en trÃ¥d innebÃ¤r att resursen tilldelas till trÃ¥den

Grafen kan anvÃ¤ndas fÃ¶r att hitta deadlocks. Exempelvis kan en cykel i grafen indikera pÃ¥ att det finns ett deadlock. Se exempel nedan:

!["Deadlock graph"](/img/deadlockgraph.png)

Notera att lÃ¥s ett och tvÃ¥ Ã¤r binÃ¤ra semaforer.

Om den fÃ¶rsta trÃ¥den tilldelas det fÃ¶rsta lÃ¥set samtidigt som den andra trÃ¥den tilldelas det andra lÃ¥set kommer ett deadlock skapas eftersom trÃ¥d ett och tvÃ¥ kommer i nÃ¤sta tur efterfrÃ¥ga en resurs som hÃ¥lls av den andra.

### 88
Hur kan man avgoÌˆra om ett system aÌˆr i deadlock med hjaÌˆlp av en resource allocation graph?

Man kan titta efter cykler i grafen. Om det finns cykler kan detta indikera att det finns deadlocks. Dock behÃ¶ver det undersÃ¶kas nÃ¤rmre.

HÃ¤r Ã¤r ett exempel:
!["Deadlock graph"](/img/deadlockgraph.png)


Notera att lÃ¥s ett och tvÃ¥ Ã¤r binÃ¤ra semaforer.

Om den fÃ¶rsta trÃ¥den tilldelas det fÃ¶rsta lÃ¥set samtidigt som den andra trÃ¥den tilldelas det andra lÃ¥set kommer ett deadlock skapas eftersom trÃ¥d ett och tvÃ¥ kommer i nÃ¤sta tur efterfrÃ¥ga en resurs som hÃ¥lls av den andra.

Om den fÃ¶rsta trÃ¥den tilldelas det fÃ¶rsta lÃ¥set samtidigt som den andra trÃ¥den tilldelas det andra lÃ¥set kommer ett deadlock skapas.

### 89
AÌˆr det ok att ignorera deadlock?

### 90
Vad aÌˆr skillnaden paÌŠ att foÌˆrhindra och undvika deadlock?

### 91
FoÌˆrklara Bankerâ€™s algoritm

### 92
Hur kan ett system aÌŠterhaÌˆmta sig fraÌŠn deadlock?

### 93
FoÌˆrklara prefix sum

### 94
FoÌˆrklara prefix scan

### 95
FoÌˆrklara odd-even transposition sort

### 96
VarfoÌˆr aÌˆr det en daÌŠlig ideÌ att skapa nya traÌŠdar foÌˆr varje rekursivt anrop i en divide and conquer-algoritm?

Det finns en risk att vi skapar vÃ¤ldigt mÃ¥nga gorutiner som i sin tur skapar en overhead vilket tar pÃ¥ datorns resurser. I en 'divide and conquer-algoritm' som quicksort sÃ¥ blir det ocksÃ¥ allt mindre arbete fÃ¶r varje rekursivt anrop, vilket kanske inte Ã¤r vÃ¤rt att skapa en helt ny gorutin fÃ¶r. Vi kan heller inte styra antalet trÃ¥dar som skapas.

### 97
VarfoÌˆr kan det vara svaÌŠrt att parallelisera rekursiva algoritmer?

Det kan vara svÃ¥rt av olika anledningar. En anledning Ã¤r att vi ofta mÃ¥ste ansÃ¤tta en gorutin till varje rekursivt anrop vilket Ã¤r problematiskt eftersom vi inte kommer ha kontroll pÃ¥ hur mÃ¥nga gorutiner som skapas. Detta kan skapa en omfattande overhead och nÃ¥gonting som vi dÃ¤rmed vill undvika.

### 98
Vad aÌˆr en barrier

En barriÃ¤r Ã¤r en samlingspunkt som ett set trÃ¥dar mÃ¥ste nÃ¥ innan nÃ¥gon av dessa trÃ¥dar fÃ¥r kÃ¶ra vidare. 

### 99
Hur kan en semafor anvaÌˆndas foÌˆr att signalera mellan traÌŠdar?

### 100
FoÌˆrklara hur depth-first search kan paralleliseras med traÌŠdar

### 101
FoÌˆrklara hur breadth-first search kan paralleliseras med traÌŠdar

### 102
FoÌˆrklara hur Primâ€™s algoritm kan paralleliseras med traÌŠdar

### 103
Vi kan hitta det minsta vaÌˆrdet i en lista paÌŠ linjaÌˆr tid (ğ‘‚(ğ‘ )). Hur laÌŠng tid tar det att koÌˆra med
ğ‘ƒ procecssorer? Motivera.

Vi kan dela upp listan i P segment dÃ¤r P processerorer kollar varsitt segment parallellt. Tidskomplexiteten blir hÃ¤r $O(\frac{N}{P})$.  Varje processor returnerar sedan det minsta vÃ¤rdet frÃ¥n sitt segment. Sedan mÃ¥ste en linjÃ¤r sÃ¶kning gÃ¶ras efter det minsta vÃ¤rdet pÃ¥ den lista av returnerade vÃ¤rden. MÃ¤ngden av dessa vÃ¤rden Ã¤r P eftersom vi har P processer som returnerar varsitt vÃ¤rde. Tidskomplexiteten blir till sist $O(\frac{N}{P} + P)$.

### 104
Vad kraÌˆvs foÌˆr att vi skall erhaÌŠlla en speedup paÌŠ ğ‘ƒ med en algorim som koÌˆrs paÌŠ ğ‘ƒ procecssorer

### 105
AÌˆr det alltid snabbare att parallelisera en algoritm och koÌˆra den paÌŠ saÌŠ maÌŠnga processorer som moÌˆjligt? Motivera.

Nej. Eftersom det kan vara kostsamt fÃ¶r datorn att skapa och kÃ¶ra mÃ¥nga processer samtidigt sÃ¥ Ã¤r det inte alltid snabbare att parallelisera pÃ¥ sÃ¥ mÃ¥nga processer sÃ¥ mÃ¶jligt. Ett exemepel pÃ¥ ett sammanhang dÃ¤r det Ã¤r dÃ¥ligt att parallelisera sÃ¥ mycket som mÃ¶jligt Ã¤r frÃ¥ga 103. I 103 kom vi fram till att tidskomplexiteten fÃ¶r att hitta det minsta vÃ¤rdet med P processer var $O(\frac{N}{P} + P)$. Om vi ansÃ¤tter sÃ¥ mÃ¥nga processer som mÃ¶jligt behÃ¶ver vi ansÃ¤tta $N=P$ vilket ger oss tidskomplexiteten $O(\frac{N}{P} + P) = O(\frac{N}{N} + N) = O(N + 1)=O(N)$. HÃ¤r kommer vi tillbaka till tidskomplexiteten fÃ¶r det seriella fallet. 


### 106
FoÌˆrklara N-ary-soÌˆkning.

### 107
FoÌˆrklara hur N-ary-soÌˆkning kan paralleliseras med traÌŠdar

### 108
FoÌˆrklara lock free

Lock free Ã¤r en lÃ¥sningsstrategi dÃ¤r man vill ta bort sÃ¥ mycket av lÃ¥sningen som mÃ¶jligt i programmet. I stÃ¤llet anvÃ¤nder man verktyg som atomÃ¤ra variabler som garanterar att operationerna pÃ¥ dessa sker pÃ¥ en atomÃ¤r nivÃ¥. Det betyder att vi inte kommer fÃ¥ nÃ¥gra race conditions fÃ¶r dessa variabler. I kritiska sektioner lÃ¥ter man processer i stÃ¤llet fÃ¶rsÃ¶ka att gÃ¥ in och utfÃ¶ra arbetet i den kritiska sektionen fÃ¶r att sedan gÃ¶ra om det om det skulle gÃ¥ fel.

En lock free algoritm Ã¤r fri frÃ¥n deadlocks och garanterar progression fÃ¶r programmet. Det finns dock en risk fÃ¶r starvation fÃ¶r vissa processer.

### 109
FoÌˆrklara wait free

Wait free Ã¤r i mÃ¥nga avseenden lock free men bÃ¤ttre eftersom den garanterar progression per process i stÃ¤llet fÃ¶r progression fÃ¶r programmet. Det innebÃ¤r att processerna aldrig upplever starvation.

### 110
Vad menas med en optimistisk algoritm (med avseende paÌŠ oÌˆmesidig uteslutning)?

En optimistisk algoritm med avseende pÃ¥ Ã¶msesidig uteslutning Ã¤r algoritmer som Ã¤r icke-blockerande, vilket innebÃ¤r att flera trÃ¥dar fÃ¥r arbeta pÃ¥ samma resurs samtidigt utan lÃ¥sning eller med minimal lÃ¥sning. FÃ¶r att fÃ¶rhindra hÃ¤ndelser som att tvÃ¥ trÃ¥dar fÃ¶rsÃ¶ker gÃ¶ra Ã¤ndringar i en minnesadress samtidigt, lÃ¥ter man varje trÃ¥d lÃ¤sa minneadressens tillstÃ¥nd innan den bÃ¶rjar konstruera den data som ska sparas dÃ¤r. Sedan LÃ¤ser man in tillstÃ¥ndet igen och bekrÃ¤ftar att den Ã¶verensstÃ¤mmer med den fÃ¶rgÃ¥ende lÃ¤sningen. Till sist skriver man in datan pÃ¥ minnesadressen. Den trÃ¥d som gÃ¶r sin andra inlÃ¤sning som kommer visa sig inte stÃ¤mma Ã¶verens med den fÃ¶rsta kommer fÃ¥ bÃ¶rja om och fÃ¶rsÃ¶ka igen.

### 111
FoÌˆrklara compare and set

### 112
Visa hur compare and set kan anvaÌˆndas foÌˆr att implementera en binaÌˆr semafor

### 113
FoÌˆrklara hand over hand locking

Hand over hand locking Ã¤r ett lÃ¥sningsprotokoll som anvÃ¤nds fÃ¶r att parallella trÃ¥dar ska kunna gÃ¶ra operationer pÃ¥ exempelvis datastrukturer utan att race conditions skapas. Hur hand over hand locking kan fÃ¶rklaras med hjÃ¤lp av ett exempel. SÃ¤g att vi har en lÃ¤nkad datastruktur som man endast kan lÃ¶pa igenom i en riktning. Vi har ocksÃ¥ en serie trÃ¥dar som Ã¤mnar gÃ¶ra operationer som ADD, DELETE och UPDATE pÃ¥ listan. FÃ¶r att utfÃ¶ra dessa sÃ¤kert behÃ¶ver vi fÃ¶rst lÃ¥ta alla element i listan ha en binÃ¤r semafor. NÃ¤r en trÃ¥d sedan bÃ¶rjar lÃ¶pa igenom listan bÃ¶rjar den fÃ¶rst med att lÃ¥sa det fÃ¶rsta elementet, sedan det andra. Sedan slÃ¤pper den fÃ¶rsta fÃ¶r att sedan lÃ¥sa det tredje. TrÃ¥den slÃ¤pper sedan det andra fÃ¶r att sedan lÃ¥sa det fjÃ¤rde osv. Processen fortsÃ¤tter tills den nÃ¥r det elementet den sÃ¶ker. Detta element skulle kunna vara det sista elementet dÃ¥ den kanske gÃ¶r en ADD.

### 114
Vad aÌˆr nackdelarna med att laÌŠsa â€œfoÌˆr mycketâ€?

HÃ¤r Ã¤r nÃ¥gra nackdelar med att lÃ¥sa "fÃ¶r mycket"

- TrÃ¥darna som kÃ¶rs och efterfrÃ¥gar lÃ¥sresurserna kan ligga och vÃ¤nta vid flera tillfÃ¤llen. NÃ¤r trÃ¥darna vÃ¤ntar gÃ¶r de ingenting vilket blir ett slÃ¶seri med datorns resurser.
- Att gÃ¶ra flera lÃ¥sningar minne och tid i form av operationer vilket gÃ¶r programmet lÃ¥ngsammare.
- Programmet kan bete sig mer synkront istÃ¤llet fÃ¶r asynkront vilket dÃ¥ besegrar syftet med att programmera asynkront. Ett exempel Ã¤r om vi har en lista som bara en trÃ¥d kan sÃ¤tta in vÃ¤rden i Ã¥t gÃ¥ngen.

### 115
Vad aÌˆr nackdelarna med att laÌŠsa â€œfoÌˆr liteâ€?

Den stÃ¶rsta nackdelen med att lÃ¥sa fÃ¶r lite Ã¤r fÃ¶rmodligen risken du skapar fÃ¶r data korruption pÃ¥ grund av race conditions.

### 116
Vad aÌˆr foÌˆrdelarna med en optimistisk algoritm (med avseende paÌŠ laÌŠsning)?

En av fÃ¶rdelerna med en optimistisk algoritm Ã¤r att du lÃ¥ser betydligt mindre, och i vissa algoritmer kanske du inte lÃ¥ser alls, vilket betyder att du sparar minne och tid (beror dock pÃ¥).

### 117
Vad aÌˆr nackdelarna med en optimistisk algoritm (med avseende paÌŠ laÌŠsning)?

### 118
FoÌˆrklara hur radering i en laÌˆnkad lista kan implementeras med en optimistisk algoritm

### 119
Ange naÌŠgra problem med att skriva flertraÌŠdade program

HÃ¤r Ã¤r nÃ¥gra problem som Ã¤r relaterat till att skriva flertrÃ¥dade program:

- Race conditions - Det fÃ¶rekommer i flera sammanhang nÃ¤r trÃ¥dar ska dela ett och samma minne. HÃ¤ndelsen att tvÃ¥ eller fler trÃ¥dar fÃ¶rsÃ¶ker skriva till samma minnesadress samtidigt kan skapa data korruption eftersom datan pÃ¥ en minnesadress Ã¤r mÃ¥nga gÃ¥nger beroende av en sekventiell hantering fÃ¶r att datan ska fÃ¶rbli konsekvent med vÃ¥ra fÃ¶rvÃ¤ntningar. 

- Deadlocks - Ett deadlock orsakas nÃ¤r varje trÃ¥d i ett set av trÃ¥dar invÃ¤ntar en hÃ¤ndelse som endast kan orsakas av en annan trÃ¥d i setet fÃ¶r att kunna gÃ¥ vidare sin exekvering. Programmet som helhet rÃ¶r sig inte framÃ¥t pÃ¥ grund av detta vilket Ã¤r ett problem.

- Exklusivitet - Ditt program kan ha kritiska regioner i sig som fÃ¶rutsÃ¤tter att endast en trÃ¥d i taget kan vara dÃ¤r. Detta fÃ¶rusÃ¤tter nÃ¥gon slags exklusiv tillgÃ¥ng till regionen. Ett problem Ã¤r hur man ska skapa denna exklusivitet.

### 120
VarfoÌˆr kan det vara svaÌŠrt att saÌˆtta samman (compose) flera flertraÌŠdade funktioner?

### 121
Vad aÌˆr en Future?

### 122
FoÌˆrklara begreppet goroutine

Enligt golangs hemsida Ã¤r en goroutine en "lightweight thread" som kan exekveras parallellt med annan kod.

### 123
FoÌˆrklara begreppet cooperative multitasking

### 124
FoÌˆrklara begreppet asynchronous programming

'Asynchronous programming' Ã¤r ett sÃ¤tt att programmera som gestaltas av en icke-blockerande struktur. Det innebÃ¤r att ett program fÃ¥r exekvera och kÃ¶ra flera kodsegment samtidigt till skillnad frÃ¥n Â´synchronous programmingÂ´som hade kÃ¶rt dessa kodsegment sekventiellt.

### 125
FoÌˆrklara begreppet callback

### 126
Vad haÌˆnder om en blockerade funktion koÌˆrs av en funktion paÌŠ event loop

### 127
NaÌˆr boÌˆr man anvaÌˆnda asynchronous programming?
Det bÃ¶r anvÃ¤ndas i sammanhang dÃ¤r ett programmeringsproblem kan delas upp i olika delar dÃ¤r dessa delar har ett lÃ¶st beroende eller ett oberoende till varandra . Summan av delarnas lÃ¶sningar blir sedan lÃ¶sningen till sjÃ¤lva problemet. Exempelvis att hitta det minsta vÃ¤rdet i en lista kan lÃ¶sas med hjÃ¤lp av 'asynchronous programmingÂ´ genom att lÃ¥ta parallella processer/trÃ¥dar kolla igenom ett set av indexintervall som tillsammans utgÃ¶r listans indexintervall. FÃ¶r varje intervall letar en process/trÃ¥d efter det minsta vÃ¤rdet i det intervallet fÃ¶r att sedan rapportera det till nÃ¥gon gemensam resurs. Sedan kan en annan process/trÃ¥d lÃ¤sa ifrÃ¥n den resursen och reda ut vilket vÃ¤rde som Ã¤r stÃ¶rst.

### 128
Vad aÌˆr en kanal i Go?
En kanal i Go Ã¤r mer eller mindre Ã¤n trÃ¥dsÃ¤ker/processÃ¤ker FIFO kÃ¶ som parallellt kÃ¶rande processer/trÃ¥dar kan skriva vÃ¤rden till och lÃ¤sa vÃ¤rden i frÃ¥n.

### 129
Vad goÌˆr select i Go?
Select Ã¤r en konsktruktion i go som anvÃ¤nds i samband med kanaler dÃ¤r den slumpmÃ¤ssigt vÃ¤ljer att lÃ¤sa ett vÃ¤rde frÃ¥n nÃ¥gon av kanalerna som har vÃ¤rden pÃ¥ sig. De tomma ignoreras tills det finns vÃ¤rden pÃ¥ den. Detta Ã¤r anvÃ¤ndbart om vi exempelvis vill att en gorutin ska kunna lÃ¤sa frÃ¥n flera kanaler och gÃ¶ra arbete A frÃ¥n kanal A och arbete B frÃ¥n kanal B. HÃ¤r Ã¤r ett kort exempel.

```go
package main

import (
    "sync"
    "fmt"
    "time"
)

func main() {
    intChan := make(chan int)
    strChan := make(chan string)
    doneChan := make(chan any)

    var wg sync.WaitGroup

    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            worker(intChan, strChan, doneChan)
        }()
    }
    
    wg.Add(1)
    go func() {
        defer wg.Done()
        time.Sleep(time.Second * 3)
        close(doneChan)
    }()

    wg.Wait()
    fmt.Println("Program is done")
}

func worker(intChan <-chan int, strChan <-chan string, doneChan chan any) {
    for {
        select {
        case <- intChan: 
            // DO A
        case <- strChan: 
            // DO B
        case _, ok := <- doneChan: 
            if (!ok) {
                return
            }
        }
        
    }
}
```

### 130
FoÌˆrklara begreppet done-kanal

En done-kanal Ã¤r en kanal som anvÃ¤nds fÃ¶r att kommunicera till gorutiner att de kan stÃ¤ngas. Exempelvis om en serie gorutiner letar efter nÃ¥got och en gorutine hittar det man letar efter sÃ¥ kan denna rutin meddela nÃ¥gon instans som stÃ¤nger done-kanalen och dÃ¤rmed alla gorutiner.

### 131
Visa (i Go-liknande kod) hur en goroutine kan avslutas med hjaÌˆlp av en done-kanal

```go
package main

import (
    "sync"
    "time"
    "fmt"
    )

func main() {
    var wg sync.WaitGroup
    doneChan := make(chan any)
    
    wg.Add(1)
    go func() {
        defer wg.Done()
        worker(doneChan)
    }()

    wg.Add(1)
    go func() {
        defer wg.Done()
        time.Sleep(time.Seconds * 5)
        close(doneChan)
    }()

    wg.Wait()
}

func worker(doneChan <-chan any) {
    for {
        select {
        case _, ok := <- doneChan:
            if !ok {
                return
            }
        default:
        fmt.Println("Doing work...")
        time.Sleep(time.Second)
        }
    }
}
```
I det hÃ¤r programmet skapar vi en function kallad 'worker' som en gorutin kÃ¶r. Funktionen skapar en while-loop dÃ¤r det utfÃ¶rs nÃ¥got arbete under raden default sÃ¥ lÃ¤nge 'doneChan' Ã¤r Ã¶ppen. NÃ¤r 'doneChan' stÃ¤ngs kommer '!ok' vara sann och 'return' kommer kÃ¶ras vilket avslutar funktionen och dÃ¤rmed gorutinen.


### 132
Implementera en funktion i Go som bestaÌˆmmer det stoÌˆrsta vaÌˆrdet som skickas paÌŠ en kanal

```go
package main

import (
	"fmt"
	"math"
	"math/rand"
)

func main() {
    intChan := make(chan int, 100)
    amount := 100
    go sendValues(amount, intChan)
    b := biggestValue(amount, intChan)
    fmt.Println("Biggest value:", b)
}

// HERE IS THE FUNCTION
func biggestValue(amount int, intChan <-chan int) int {
    biggestValue := math.MinInt
    for i := 0; i < amount; i++ {
        x := <- intChan
        if x > biggestValue {
            biggestValue = x
        }
    }
    return biggestValue
}

func sendValues(amount int, intChan chan<- int) {
    for i := 0; i < amount; i++ {
        intChan <- rand.Intn(1001)
    }
}
```

### 133
Implementera en funktion i Go som delar en kanal i flera kanaler (multiplex)

### 134
Vad aÌˆr ett closure i Go?

En closure Ã¤r en funktion som har tillgÃ¥ng till resurser som Ã¤r definierade utanfÃ¶r dess omfÃ¥ng. HÃ¤r Ã¤r ett kort exempel:
```go
package main

import "fmt"

func main() {
    x := 2

    test := func() {
        x++
    }
    test()

    fmt.Println(x)
}
```

### 135
FoÌˆrklara WaitGroup i Go

WaitGroup Ã¤r en funktionalitet som anvÃ¤nds fÃ¶r att lÃ¤gga till goroutines som ska vÃ¤ntas in tills de Ã¤r klara med sin uppgift innan programmet gÃ¥r vidare till att komma vidare i programmet eller avsluta.

HÃ¤r Ã¤r ett exempel:
```go
package main

import (
    "time"
    "sync"
    "fmt"
    )

func main() {
    var wg sync.WaitGroup

    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            time.Sleep(time.Second * 2)
        }()
    }

    wg.Wait()
    fmt.Println("Go routines are done")
}
```
Detta programmet skapar 10 goroutines som sover i 2 sekunder fÃ¶r att sedan meddela 'wg' att de Ã¤r klara. Alla goroutines vÃ¤ntas in vid 'wg.Wait()' innan programmet kÃ¶r den sista raden.

